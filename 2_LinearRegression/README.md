# Simple Linear Regression â€” From Mathematics to Code

An end-to-end implementation of **Simple Linear Regression**, built both:
- with a **clean ML pipeline**, and  
- **from scratch**, using only mathematics and NumPy.

The goal is not just to *use* linear regression, but to **fully understand how it works internally**.

---

## ğŸ“Œ What This Project Demonstrates

- translating mathematical formulas into working code  
- implementing regression **without black-box libraries**  
- correct train/test separation (no data leakage)  
- rigorous model evaluation  
- clear documentation of theory and implementation  

This is a **foundational ML project**, designed to scale into:
- multiple linear regression  
- logistic regression  
- gradient-descentâ€“based models  

---

## ğŸ“ Project Structure

2_LinearRegression/
â”‚
â”œâ”€â”€ main.py # Production-style ML pipeline
â”œâ”€â”€ mathematical_model.py # Linear regression from scratch
â”œâ”€â”€ students.csv # Hours studied â†’ Exam score
â”œâ”€â”€ steps.tex # Mathematical derivation (LaTeX)
â”œâ”€â”€ steps.pdf # Compiled derivation
â””â”€â”€ README.md

---

## ğŸ§  Concepts Covered

### Machine Learning
- train/test split  
- mean imputation  
- feature standardization (z-score)  
- training, prediction, evaluation  

### Mathematics
- hypothesis:  Å· = bâ‚€ + bâ‚x  
- least squares (closed-form solution)  
- covariance & variance  
- MSE and RÂ²  

---